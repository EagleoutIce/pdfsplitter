#!/usr/bin/env python3
#
# This program uses 'pdfsplit' to split a pdf in even chunks
# with the size of 'n'. It uses pdftk, as cpdf is commercial
#

import argparse
import os
import os.path
import subprocess
import sys
from concurrent import futures
from typing import Union

import yaml

parser = argparse.ArgumentParser(
    description="pdfsplitter. Autosplit pdfs in chunks using pdftk.", epilog="Made by Florian Sihler")

parser.add_argument('-c', '--chunksize', dest='chunksize',
                    default=90, type=int, metavar='N',
                    help='Maximum number of pages in each chunk')

parser.add_argument('-t', '--threads', dest='threads',
                    default=1, type=int, metavar='N',
                    help='Number of threads to use (only when multiple files).')

parser.add_argument('-n', '--name', dest='name',
                    default='part_{i}_{basename}.pdf', type=str,
                    help='Name of the output file. {i} is the chunk number, {basename} the basename of the file, {file} the old file name.')

parser.add_argument('-o', '--out-dir', dest='out_dir',
                    default='.', type=str, metavar='DIR',
                    help='Output folder, {file} expands to the file, {n} to the worker-id (incrementing) and {basename} expands to the file without the extension.')

parser.add_argument('-f', '--force-create', dest='force_create',
                    action='store_true',
                    help='"Split" the pdf even if all pages fit into one chunk.')

parser.add_argument('files', help='The file(s) to split.',
                    type=str, nargs='+')

if (len(sys.argv) <= 1):
    parser.parse_args(['-h'])

args = parser.parse_args()

# Check for invalid arguments

if args.chunksize <= 0:
    print('Chunksize "{c}" is not valid'.format(c=args.chunksize))
    exit(1)

if not args.out_dir.strip():
    print('The out-directory "{o}" isn\'t valid'.format(o=args.out_dir))
    exit(2)

if not args.name.strip():
    print('The name "{o}" isn\'t valid'.format(o=args.name))
    exit(3)


def get_target_filename(file: str, i: int) -> str:
    return args.name.format(
        i=i, file=file, basename=os.path.basename(os.path.splitext(file)[0])
    )


def print_idx(idx: int, *objects, sep=' ', end='\n', pre='', file=sys.stdout, flush=False):
    print(pre, "[ID " + str(idx) + "]", *objects,
          sep=sep, end=end, file=file, flush=flush)

def format_command(command: str, idx: int, i: int, out_dir: str, file: str, start: int, end: Union[int, str]) -> str:
    return command.format(
        file=file, start=start, end=end,
        output=os.path.join(
            args.out_dir,
            get_target_filename(file, i)
        ),
        basename=os.path.basename(os.path.splitext(file)[0])
    )

def produce_chunk(idx: int, i: int, out_dir: str, file: str, start: int, end: Union[int, str]):
    command = format_command('pdftk {file} cat {start}-{end} output {output}', idx, i, out_dir, file, start, end)

    # allow multiple expansion
    for i in range(0, 2):
        command = format_command(command, idx, i, out_dir, file, start, end)

    print_idx(idx, '    Executing:', command)
    os.system(command)


def process_file(idx: int, file: str):
    out_dir = args.out_dir.format(
        file=file,
        basename=os.path.basename(os.path.splitext(file)[0]),
        n=idx
    )

    if not os.path.isdir(out_dir):
        print('Out-Directory', out_dir, 'doesn\'t exist. Creating...')
        os.makedirs(out_dir, exist_ok=True)

    # Determine the real pdf sizes
    page_count: int = yaml.safe_load(
        subprocess.check_output(["pdfinfo", file]))['Pages']

    if page_count <= args.chunksize:
        print_idx(idx, 'Pdf fits', file,
                  'into one chunk. Skipping (use -f to force)')
        if not args.force_create:
            return

    previous = 1
    next_i = 0
    for i, n in enumerate(range(args.chunksize, page_count, args.chunksize)):
        print_idx(idx,
                  'Creating chunk {i} with pages: {previous} to {n}'.format(**locals()))
        produce_chunk(idx, i, out_dir, file, previous, n)
        previous = n + 1  # to avoid duplicate pages
        next_i = i + 1

    if previous <= page_count:
        print_idx(idx,
                  'Last chunk covers page(s): {previous} to {page_count}'.format(**locals()))
        produce_chunk(idx, next_i, out_dir, file, previous, 'end')
    else:
        print_idx(idx, 'No last chunk.')


with futures.ThreadPoolExecutor(max_workers=args.threads) as pool:
    runners = []
    for idx, file in enumerate(args.files):
        runners.append(pool.submit(process_file, idx, file))
    futures.wait(runners)
    for idx, runner in enumerate(runners):
        result = runner.result()
        if result is not None:
            print_idx(idx, result)

print('Finished')
exit(0)
